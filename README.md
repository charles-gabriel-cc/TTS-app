# ü§ñ Assistente Virtual CCEN - TTS App

<div align="center">

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/Python-3.10.11-blue.svg)
![React](https://img.shields.io/badge/React-18.2.0-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-latest-green.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)

**Assistente Virtual Inteligente para o Centro de Ci√™ncias Exatas e da Natureza (CCEN) da UFPE**

Um sistema completo de conversa√ß√£o por voz e texto com IA, desenvolvido especificamente para responder d√∫vidas sobre professores, departamentos e informa√ß√µes acad√™micas do CCEN.

</div>

## üåü Principais Funcionalidades

### üéØ **Sistema de IA Conversacional**
- **Chat inteligente** com modelos locais (Ollama) ou OpenAI
- **RAG (Retrieval-Augmented Generation)** com base de conhecimento espec√≠fica do CCEN
- **Busca vetorial** avan√ßada com Qdrant para respostas precisas

### üé§ **Speech-to-Text (STT)**
- Transcri√ß√£o de √°udio em tempo real com **OpenAI Whisper**
- Suporte a m√∫ltiplos idiomas (otimizado para portugu√™s)
- Interface de grava√ß√£o moderna e intuitiva

### üîä **Text-to-Speech (TTS)**
- S√≠ntese de voz natural com **Google TTS (gTTS)**
- Reprodu√ß√£o autom√°tica de respostas
- Controle de ativa√ß√£o/desativa√ß√£o por usu√°rio

### üì± **Interface Multiplataforma**
- **Web App** responsivo e moderno (Next.js + Tailwind CSS)
- **App Android** nativo com Capacitor
- **PWA** (Progressive Web App) para instala√ß√£o offline
- **Modo Kiosk** para uso em totems e dispositivos dedicados

### üé® **Design Moderno**
- Interface baseada em **shadcn/ui** components
- Anima√ß√µes suaves com **Framer Motion**
- Design responsivo e acess√≠vel
- Tema dark/light (configur√°vel)

## üèóÔ∏è Arquitetura do Sistema

```mermaid
graph TB
    A[üë§ Usu√°rio] --> B[üì± Frontend React/Next.js]
    B --> C[üîå API FastAPI]
    C --> D[üé§ Whisper STT]
    C --> E[üß† Ollama/OpenAI LLM]
    C --> F[üîä Google TTS]
    C --> G[üìä Qdrant Vector DB]
    H[üêã Docker Compose] --> I[ü¶ô Ollama Container]
    H --> J[üì¶ Qdrant Container]
    H --> K[üêç Backend Container]
    G --> L[üìö Base CCEN]
```

## üöÄ Instala√ß√£o e Configura√ß√£o

### üìã Pr√©-requisitos

#### **Sistema Operacional**
- Windows 10/11 (com WSL2 para desenvolvimento)
- Linux (Ubuntu 20.04+ recomendado)
- macOS (suporte limitado para GPU)

#### **Hardware Recomendado**
- **RAM**: 16GB+ (32GB recomendado para modelos grandes)
- **GPU**: NVIDIA com CUDA 11.8+ (opcional, mas recomendado)
- **Armazenamento**: 50GB+ livres
- **Processador**: CPU x64 com 4+ cores

#### **Software Base**
```bash
# Node.js e npm
node --version  # v18.0.0+
npm --version   # v8.0.0+

# Python
python --version  # 3.10.11

# Docker
docker --version         # 20.0.0+
docker-compose --version # 2.0.0+

# Git
git --version
```

### üîß Depend√™ncias Espec√≠ficas

#### **Windows**
```powershell
# Chocolatey (se n√£o tiver)
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))

# FFmpeg para processamento de √°udio
choco install ffmpeg

# Visual C++ Build Tools
# Download: https://visualstudio.microsoft.com/pt-br/visual-cpp-build-tools/

# CUDA Toolkit (para GPU)
# Download: https://developer.nvidia.com/cuda-11-8-0-download-archive
```

#### **Linux (Ubuntu/Debian)**
```bash
# FFmpeg
sudo apt update
sudo apt install ffmpeg

# Build essentials
sudo apt install build-essential

# CUDA (se tiver GPU NVIDIA)
# Siga: https://developer.nvidia.com/cuda-downloads
```

#### **Rust (necess√°rio para algumas depend√™ncias Python)**
```bash
# Windows/Linux/macOS
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.cargo/env
```

### üì• Clonagem e Setup Inicial

```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/seu-usuario/TTS-app.git
cd TTS-app

# 2. Configurar backend
cd backend
python -m venv tts-env
source tts-env/bin/activate  # Linux/macOS
# ou
tts-env\Scripts\activate     # Windows

pip install -r requirements.txt

# 3. Configurar frontend
cd ../tts-app-next
npm install

# 4. Preparar Docker
cd ../backend
docker-compose pull
```

### üîê Configura√ß√£o de Vari√°veis de Ambiente

Crie o arquivo `.env` no diret√≥rio `backend/`:

```bash
# === CONFIGURA√á√ïES DO SERVIDOR ===
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# === CONFIGURA√á√ïES DE IA ===
MODEL_NAME=phi4:latest          # Modelo Ollama local
USE_LOCAL_MODEL=true
EMBED_MODEL=all-minilm:l6-v2

# === CONFIGURA√á√ïES QDRANT ===
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=                 # Deixe vazio para inst√¢ncia local
USE_LOCAL_COLLECTION=true
COLLECTION_NAME=ccen-docentes

# === CONFIGURA√á√ïES OLLAMA ===
OLLAMA_BASE_URL=http://localhost:11434

# === APIS EXTERNAS (OPCIONAL) ===
OPENAI_API_KEY=sua-chave-openai-aqui  # Opcional, para usar OpenAI

# === MONITORAMENTO (OPCIONAL) ===
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=backend
LANGSMITH_API_KEY=sua-chave-langsmith  # Opcional

# === CONFIGURA√á√ïES CUDA ===
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=0
```

### üêã Inicializa√ß√£o com Docker (Recomendado)

#### **Desenvolvimento Completo**
```bash
cd backend

# Subir todos os servi√ßos
docker-compose -f docker-compose.dev.yml up --build

# Em outro terminal, aguardar servi√ßos ficarem online
# Ollama: http://localhost:11434
# Qdrant: http://localhost:6333
# Backend: http://localhost:8000
```

#### **Produ√ß√£o**
```bash
cd backend

# Produ√ß√£o otimizada
docker-compose up -d --build

# Verificar status
docker-compose ps
docker-compose logs -f tts-app
```

### üìö Download dos Modelos IA

```bash
# 1. Conectar ao container Ollama
docker exec -it tts-ollama bash

# 2. Baixar modelo principal (escolha um)
ollama pull phi4:latest        # Recomendado (7B, equilibrado)
ollama pull llama3.2:latest    # Alternativo
ollama pull mistral:latest     # Mais leve

# 3. Baixar modelo de embeddings
ollama pull all-minilm:l6-v2

# 4. Testar modelos
ollama list
```

### üéØ Configura√ß√£o da Base de Conhecimento

```bash
# 1. Conectar ao container da aplica√ß√£o
docker exec -it tts-app-backend bash

# 2. Processar documentos CCEN (se necess√°rio)
python embeddings.py

# 3. Verificar cole√ß√£o no Qdrant
curl http://localhost:6333/collections/ccen-docentes
```

### üåê Inicializa√ß√£o do Frontend

```bash
cd tts-app-next

# Desenvolvimento
npm run dev

# Produ√ß√£o
npm run build
npm run start

# HTTPS (para funcionalidades de √°udio)
npm run dev:https
```

## üì± Build do App Android

### üîß Pr√©-requisitos Android

```bash
# 1. Java JDK 21
# Download: https://adoptium.net/

# 2. Android Studio
# Download: https://developer.android.com/studio

# 3. Configurar vari√°veis de ambiente
$env:JAVA_HOME="C:\Program Files\Java\jdk-21"  # Windows
export JAVA_HOME="/usr/lib/jvm/java-21-openjdk" # Linux
```

### üì¶ Build APK

```bash
cd tts-app-next

# 1. Build web otimizado
npm run build

# 2. Sincronizar com Capacitor
npm run cap:build

# 3. Abrir no Android Studio
npm run cap:open

# 4. Build via linha de comando
cd android
./gradlew.bat assembleDebug  # Windows
./gradlew assembleDebug      # Linux/macOS
```

O APK ser√° gerado em: `android/app/build/outputs/apk/debug/`

## üéÆ Como Usar

### üíª **Interface Web**
1. Acesse: http://localhost:3000
2. **Digite** sua pergunta ou **clique no microfone** para falar
3. Ative o **switch de √°udio** para ouvir as respostas
4. Use o **bot√£o de anexo** para enviar documentos

### üì± **App Android**
1. Instale o APK gerado
2. Configure permiss√µes de **microfone** e **armazenamento**
3. Interface touch otimizada para tablets e smartphones

### ü§ñ **Exemplos de Perguntas**
```
- "Quem √© o professor Jo√£o Silva?"
- "Quais s√£o os professores do departamento de Matem√°tica?"
- "Me fale sobre o curso de Ci√™ncia da Computa√ß√£o"
- "Hor√°rios do professor Maria Santos"
- "Contato do departamento de F√≠sica"
```

## üõ†Ô∏è Scripts de Desenvolvimento

### üîß **Backend**
```bash
cd backend

# Iniciar servidor de desenvolvimento
python server.py

# Interface Gradio alternativa
python app.py

# Scripts automatizados
.\start_backend.bat                    # Windows simples
.\start_backend_interactive.bat       # Windows interativo
.\start_backend_universal.bat         # Windows universal
./start_backend.sh                    # Linux/macOS
```

### üé® **Frontend**
```bash
cd tts-app-next

# Desenvolvimento
npm run dev              # Padr√£o
npm run dev:https        # Com HTTPS

# Build e deploy
npm run build           # Build produ√ß√£o
npm run start           # Servidor produ√ß√£o
npm run preview         # Preview local

# Capacitor Android
npm run cap:init        # Inicializar
npm run cap:build       # Build e sync
npm run cap:run         # Build e executar
npm run cap:dev         # Modo desenvolvimento
```

## üê≥ Comandos Docker √öteis

### üîÑ **Gerenciamento B√°sico**
```bash
# Parar todos os servi√ßos
docker-compose down

# Restart espec√≠fico
docker-compose restart tts-app
docker-compose restart ollama

# Logs em tempo real
docker-compose logs -f
docker-compose logs -f tts-app

# Status dos containers
docker-compose ps
```

### üßπ **Limpeza e Reset**
```bash
# ‚ö†Ô∏è ATEN√á√ÉO: Remove TODOS os dados!

# Parar containers
docker-compose down

# Remover volumes (apaga modelos e dados)
docker volume rm backend_ollama_data backend_qdrant_data

# Rebuild completo
docker-compose up --build --force-recreate
```

### üîç **Debug e Monitoramento**
```bash
# Conectar aos containers
docker exec -it tts-app-backend bash      # Backend Python
docker exec -it tts-ollama bash           # Ollama
docker exec -it tts-qdrant bash           # Qdrant

# Monitorar recursos
docker stats

# Verificar volumes
docker volume ls
docker volume inspect backend_ollama_data
```

## üö® Solu√ß√£o de Problemas

### ‚ùå **Problemas Comuns**

#### **Docker n√£o inicia**
```bash
# Windows: Verificar WSL2
wsl --status
wsl --update

# Linux: Verificar permiss√µes
sudo usermod -aG docker $USER
newgrp docker
```

#### **Ollama n√£o carrega modelos**
```bash
# Verificar espa√ßo em disco
df -h

# Redownload do modelo
docker exec -it tts-ollama ollama pull phi4:latest

# Verificar mem√≥ria
docker exec -it tts-ollama ollama list
```

#### **Qdrant n√£o conecta**
```bash
# Verificar se est√° rodando
curl http://localhost:6333/health

# Restart for√ßado
docker-compose restart qdrant
```

#### **Audio n√£o funciona (Web)**
- Usar **HTTPS** (required by browsers): `npm run dev:https`
- Verificar **permiss√µes** do navegador
- **Chrome flags**: chrome://flags ‚Üí "Experimental Web Platform features"

#### **Build Android falha**
```bash
# Limpar cache Gradle
cd android
./gradlew clean

# Verificar JAVA_HOME
echo $JAVA_HOME

# Rebuild
npm run cap:build
```

### üìä **Monitoramento**

#### **Health Checks**
```bash
# Backend API
curl http://localhost:8000/health

# Ollama
curl http://localhost:11434/api/tags

# Qdrant
curl http://localhost:6333/health

# Frontend
curl http://localhost:3000
```

#### **Logs Importantes**
```bash
# Backend detalhado
docker-compose logs -f tts-app

# Ollama responses
docker-compose logs -f ollama

# Banco vetorial
docker-compose logs -f qdrant
```

## üîß Configura√ß√µes Avan√ßadas

### ‚ö° **Otimiza√ß√£o de Performance**

#### **WSL2 (Windows)**
Crie/edite `%USERPROFILE%\.wslconfig`:
```ini
[wsl2]
memory=16GB
processors=8
localhostForwarding=true
```

#### **CUDA Memory**
```bash
# Verificar GPU
nvidia-smi

# Ajustar no docker-compose.yml
environment:
  - CUDA_VISIBLE_DEVICES=0
  - NVIDIA_VISIBLE_DEVICES=all
```

### üåê **Deploy em Produ√ß√£o**

#### **Nginx Proxy (Recomendado)**
```nginx
server {
    listen 80;
    server_name seu-dominio.com;
    
    location /api/ {
        proxy_pass http://localhost:8000/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    location / {
        proxy_pass http://localhost:3000/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

#### **SSL/HTTPS Setup**
```bash
# Certbot (Let's Encrypt)
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d seu-dominio.com
```

## üìö Documenta√ß√£o Adicional

- üì± [**Guia de Build Android**](tts-app-next/APK-BUILD-GUIDE.md)
- üîó [**Guia de Conectividade**](tts-app-next/CONNECTIVITY-GUIDE.md)
- üñ•Ô∏è [**Modo Tela Cheia**](tts-app-next/FULLSCREEN-GUIDE.md)
- üîí [**Configura√ß√£o HTTPS**](tts-app-next/HTTPS-SETUP.md)
- üîß [**Guia de Integra√ß√£o**](tts-app-next/INTEGRATION_GUIDE.md)
- üì∫ [**Modo Kiosk**](tts-app-next/KIOSK-MODE-GUIDE.md)
- üì≤ [**Convers√£o Mobile**](tts-app-next/MOBILE-CONVERSION-GUIDE.md)
- üêã [**Docker Setup**](README-DOCKER.md)

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o muito bem-vindas! Por favor:

1. **Fork** o reposit√≥rio
2. Crie uma **branch** para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. Abra um **Pull Request**

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üè´ Sobre o CCEN/UFPE

Este assistente foi desenvolvido especificamente para o **Centro de Ci√™ncias Exatas e da Natureza (CCEN)** da **Universidade Federal de Pernambuco (UFPE)**, visando facilitar o acesso a informa√ß√µes sobre professores, departamentos e recursos acad√™micos.

---

<div align="center">

**Desenvolvido com ‚ù§Ô∏è para a comunidade acad√™mica do CCEN/UFPE**

[üåê UFPE](https://www.ufpe.br) ‚Ä¢ [üè´ CCEN](https://www.ufpe.br/ccen)

</div>